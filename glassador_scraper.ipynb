{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in f:\\siika\\python\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: trio~=0.17 in f:\\siika\\python\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in f:\\siika\\python\\lib\\site-packages (from selenium) (2022.6.15)\n",
      "Collecting urllib3[socks]~=1.26\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.6/140.6 kB 214.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: trio-websocket~=0.9 in f:\\siika\\python\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: idna in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (1.0.1)\n",
      "Requirement already satisfied: sniffio in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in f:\\siika\\python\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in f:\\siika\\python\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in f:\\siika\\python\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in f:\\siika\\python\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in f:\\siika\\python\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.23\n",
      "    Uninstalling urllib3-1.23:\n",
      "      Successfully uninstalled urllib3-1.23\n",
      "Successfully installed urllib3-1.26.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.15.1 requires jinja2>=3.0.3, but you have jinja2 2.11.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\siika\\python\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from shutil import which\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, ElementNotInteractableException\n",
    "import time\n",
    "from lxml import html\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs(keyword, num_pages,path):\n",
    "    options = Options()\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    #Enter your chromedriver.exe path below\n",
    "    chrome_path= path\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path, options=options)\n",
    "    url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=\"' + keyword + '\"&locT=C&locId=1147401&locKeyword=San%20Francisco,%20CA&jobType=all&fromAge=-1&minSalary=0&includeNoSalaryJobs=true&radius=100&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&seniorityType=all&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0'\n",
    "\n",
    "    driver.get(url)\n",
    "  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    company_name = []\n",
    "    job_title = []\n",
    "    salary_est = []\n",
    "    location = []\n",
    "    job_description = []\n",
    "    salary_estimate = []\n",
    "    company_size = []\n",
    "    company_type = []\n",
    "    company_sector = []\n",
    "    company_industry = []\n",
    "    company_founded = []\n",
    "    company_revenue = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Set current page to 1\n",
    "    current_page = 1     \n",
    "        \n",
    "        \n",
    "    time.sleep(3)\n",
    "    \n",
    "    while current_page <= num_pages:   \n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            job_cards = driver.find_elements(By.XPATH,\"//article[@id='MainCol']//ul/li[@data-adv-type='GENERAL']\")\n",
    "            for card in job_cards:\n",
    "                card.click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                #Closes the signup prompt\n",
    "                try:\n",
    "                    driver.find_element(By.XPATH,\".//span[@class='SVGInline modal_closeIcon']\").click()\n",
    "                    time.sleep(1)\n",
    "                except NoSuchElementException:\n",
    "                    time.sleep(2)\n",
    "                    pass\n",
    "\n",
    "                #Expands the Description section by clicking on Show More\n",
    "                opened=False\n",
    "                while not opened:\n",
    "                    try:\n",
    "                        driver.find_element(By.XPATH,\"//div[@class='css-t3xrds e856ufb5']\").click()\n",
    "                        time.sleep(1)\n",
    "                        opened=True\n",
    "                    except NoSuchElementException:\n",
    "                        card.click()\n",
    "                        print(str(current_page) + '#ERROR: no such element')\n",
    "                        time.sleep(2)\n",
    "                    \n",
    "                #Scrape \n",
    "\n",
    "                try:\n",
    "                    company_name.append(driver.find_element(By.XPATH,\"//div[@class='css-87uc0g e1tk4kwz1']\").text)\n",
    "                except:\n",
    "                    company_name.append(\"#N/A\")\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    job_title.append(driver.find_element(By.XPATH,\"//div[@class='css-1vg6q84 e1tk4kwz4']\").text)\n",
    "                except:\n",
    "                    job_title.append(\"#N/A\")\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    location.append(driver.find_element(By.XPATH,\"//div[@class='css-56kyx5 e1tk4kwz5']\").text)\n",
    "                except:\n",
    "                    location.append(\"#N/A\")\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    job_description.append(driver.find_element(By.XPATH,\"//div[@id='JobDescriptionContainer']\").text)\n",
    "                except:\n",
    "                    job_description.append(\"#N/A\")\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    salary_estimate.append(driver.find_element(By.XPATH,\"//div[@class='css-1bluz6i e2u4hf13']\").text)\n",
    "                except:\n",
    "                    salary_estimate.append(\"#N/A\")\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    company_size.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Size']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_size.append(\"#N/A\")\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    company_type.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Type']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_type.append(\"#N/A\")\n",
    "                    pass\n",
    "                    \n",
    "                try:\n",
    "                    company_sector.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Sector']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_sector.append(\"#N/A\")\n",
    "                    pass\n",
    "                    \n",
    "                try:\n",
    "                    company_industry.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Industry']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_industry.append(\"#N/A\")\n",
    "                    pass\n",
    "                    \n",
    "                try:\n",
    "                    company_founded.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Founded']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_founded.append(\"#N/A\")\n",
    "                    pass\n",
    "                    \n",
    "                try:\n",
    "                    company_revenue.append(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Revenue']//following-sibling::*\").text)\n",
    "                except:\n",
    "                    company_revenue.append(\"#N/A\")\n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                done = True\n",
    "                \n",
    "       # Moves to the next page         \n",
    "        if done:\n",
    "            print(str(current_page) + ' ' + 'out of' +' '+ str(num_pages) + ' ' + 'pages done')\n",
    "            driver.find_element(By.XPATH,\"//span[@alt='next-icon']\").click()   \n",
    "            current_page = current_page + 1\n",
    "            time.sleep(4)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "    df = pd.DataFrame({'company': company_name, \n",
    "    'job title': job_title,\n",
    "    'location': location,\n",
    "    'job description': job_description,\n",
    "    'salary estimate': salary_estimate,\n",
    "    'company_size': company_size,\n",
    "    'company_type': company_type,\n",
    "    'company_sector': company_sector,\n",
    "    'company_industry' : company_industry, 'company_founded' : company_founded, 'company_revenue': company_revenue})\n",
    "    \n",
    "    df.to_csv(keyword+ '.csv')\n",
    "                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.glassdoor.com/Job/remote-data-scientist-jobs-SRCH_IL.0,6_IS11047_KO7,21.htm?src=GD_JOB_AD&srs=ALL_RESULTS&jl=1008388739369&ao=1136043&s=345&guid=0000018591b74fdb9be4ca1dfb5ff146&pos=102&t=SR-JOBS-HR&vt=w&uido=C9591E0F2E81C40321839CEF58B3CF51&ea=1&cs=1_054c9b5e&cb=1673186988585&jobListingId=1008388739369&jrtk=3-0-1gm8rek13m6qv801-1gm8rekb1irm6800-b146a6fa7d55e63f-\"\n",
    "def scrape_one_job(job_card_url,path):\n",
    "    options = Options()\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    #Enter your chromedriver.exe path below\n",
    "    chrome_path = path\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path, options=options)\n",
    "  # Navigate to the job card page\n",
    "    driver.get(job_card_url)    \n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    opened=False\n",
    "    while not opened:\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,\"//div[@class='css-t3xrds e856ufb4']\").click()\n",
    "            time.sleep(1)\n",
    "            opened=True\n",
    "        except NoSuchElementException:\n",
    "            print('#ERROR: no such element')\n",
    "            time.sleep(2)    \n",
    "    # Extract the data for the job\n",
    "    try:\n",
    "        company_name=(driver.find_element(By.XPATH,\"//div[@class='css-87uc0g e1tk4kwz1']\").text)\n",
    "    except:\n",
    "        company_name=(\"#N/A\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        job_title=(driver.find_element(By.XPATH,\"//div[@class='css-1vg6q84 e1tk4kwz4']\").text)\n",
    "    except:\n",
    "        job_title=(\"#N/A\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        location=(driver.find_element(By.XPATH,\"//div[@class='css-56kyx5 e1tk4kwz5']\").text)\n",
    "    except:\n",
    "        location=(\"#N/A\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        job_description=(driver.find_element(By.XPATH,\"//div[@id='JobDescriptionContainer']\").text)\n",
    "    except:\n",
    "        job_description=(\"#N/A\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        salary_estimate=(driver.find_element(By.XPATH,\"//div[@class='css-1bluz6i e2u4hf13']\").text)\n",
    "    except:\n",
    "        salary_estimate=(\"#N/A\")\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        company_size=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Size']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_size=(\"#N/A\")\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        company_type=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Type']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_type=(\"#N/A\")\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        company_sector=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Sector']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_sector=(\"#N/A\")\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        company_industry=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Industry']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_industry=(\"#N/A\")\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        company_founded=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Founded']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_founded=(\"#N/A\")\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        company_revenue=(driver.find_element(By.XPATH,\"//div[@id='CompanyContainer']//span[text()='Revenue']//following-sibling::*\").text)\n",
    "    except:\n",
    "        company_revenue=(\"#N/A\")\n",
    "        pass\n",
    "\n",
    "    # Save the data for the job\n",
    "    job = {\n",
    "      'company_name': company_name,\n",
    "      'job_title': job_title,\n",
    "      'location': location,\n",
    "      'job_description': job_description,\n",
    "      'company_size': company_size,\n",
    "      'company_type': company_type,\n",
    "      'company_sector': company_sector,\n",
    "      'company_industry': company_industry,\n",
    "      'company_founded': company_founded,\n",
    "      'company_revenue': company_revenue\n",
    "    }\n",
    "    \n",
    "    \n",
    "  # Close the webdriver\n",
    "    driver.quit()\n",
    "\n",
    "    return job\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msiik\\AppData\\Local\\Temp\\ipykernel_24288\\2507192715.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, options=options)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'company_name': 'Net2Aspire',\n",
       "  'job_title': 'Jr. Data Scientist',\n",
       "  'location': 'Remote',\n",
       "  'salary_estimate': '$72,500 /yr (est.)',\n",
       "  'job_description': '\\uf0b7 Apply Statistical and Machine Learning methods to specific business problems and data.\\n\\uf0b7 Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.\\n\\uf0b7 Using tools such as Tableau, Looker and GoogleData Studio to aggregate data from across our software tools to build and develop dashboards for both client-facing and internal purposes across the company that feature relevant KPIs and metrics\\n\\uf0b7 Create data dashboards and other data visualization tools to track progress to inform continuous quality improvement of the Congregate Settings Investigation and Response Unit.\\n\\uf0b7 Design, develop, evaluate, and release highly innovative models elevate the customer experience and track impact over time\\nJob Types: Full-time, Part-time, Contract\\nSalary: $65,000.00 - $80,000.00 per year\\nBenefits:\\n401(k)\\nHealth insurance\\nSchedule:\\n8 hour shift\\nMonday to Friday\\nExperience:\\nData science: 1 year (Required)\\nMachine learning: 1 year (Required)\\nWork Location: Remote\\nShow Less\\nReport',\n",
       "  'company_size': 'Unknown',\n",
       "  'company_type': 'Company - Public',\n",
       "  'company_sector': '#N/A',\n",
       "  'company_industry': '#N/A',\n",
       "  'company_founded': '#N/A',\n",
       "  'company_revenue': 'Unknown / Non-Applicable'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromepath=\"F:/siika/repos/Jobs_salary_Prediction/chromedriver\"\n",
    "scrape_one_job(url,chromepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msiik\\AppData\\Local\\Temp\\ipykernel_9628\\1985035490.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 24 pages done\n",
      "2#ERROR: no such element\n",
      "2#ERROR: no such element\n",
      "2 out of 24 pages done\n",
      "3#ERROR: no such element\n",
      "3 out of 24 pages done\n",
      "4#ERROR: no such element\n",
      "4#ERROR: no such element\n",
      "4 out of 24 pages done\n",
      "5#ERROR: no such element\n",
      "5 out of 24 pages done\n",
      "6#ERROR: no such element\n",
      "6 out of 24 pages done\n",
      "7 out of 24 pages done\n",
      "8 out of 24 pages done\n",
      "9#ERROR: no such element\n",
      "9 out of 24 pages done\n",
      "10 out of 24 pages done\n",
      "11#ERROR: no such element\n",
      "11 out of 24 pages done\n",
      "12#ERROR: no such element\n",
      "12#ERROR: no such element\n",
      "12#ERROR: no such element\n",
      "12 out of 24 pages done\n",
      "13 out of 24 pages done\n",
      "14 out of 24 pages done\n",
      "15#ERROR: no such element\n",
      "15#ERROR: no such element\n",
      "15 out of 24 pages done\n",
      "16 out of 24 pages done\n",
      "17 out of 24 pages done\n",
      "18 out of 24 pages done\n",
      "19#ERROR: no such element\n",
      "19 out of 24 pages done\n",
      "20#ERROR: no such element\n",
      "20 out of 24 pages done\n",
      "21 out of 24 pages done\n",
      "22#ERROR: no such element\n",
      "22#ERROR: no such element\n",
      "22 out of 24 pages done\n",
      "23#ERROR: no such element\n",
      "23 out of 24 pages done\n",
      "24#ERROR: no such element\n",
      "24#ERROR: no such element\n",
      "24#ERROR: no such element\n",
      "24#ERROR: no such element\n",
      "24 out of 24 pages done\n"
     ]
    }
   ],
   "source": [
    "chromepath=\"F:/siika/repos/Jobs_salary_Prediction/chromedriver\"\n",
    "fetch_jobs(\"Data Scientist\",24,chromepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data Scientist.csv\")\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2a32ab4a5f7cd90480dbabb09257fae3defe07d2d8fed2a66cce74ba4c49416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
